main train dataset preparing...
librispeech class load dataset...
Resolving data files: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 282.97it/s]
Resolving data files: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:00<00:00, 220269.79it/s]
Resolving data files: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 544546.42it/s]
Resolving data files: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:00<00:00, 62601.55it/s]
Loading dataset shards: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 23/23 [00:00<00:00, 119.61it/s]
main eval dataset preparing...
librispeech class load dataset...
Resolving data files: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 352321.54it/s]
Resolving data files: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:00<00:00, 233016.89it/s]
Resolving data files: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 73476.86it/s]
Resolving data files: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:00<00:00, 205855.41it/s]
Epoch 0:   0%|                                                                                                                              | 0/500 [00:02<?, ?it/s]
Traceback (most recent call last):
  File "/home/kyudan/WhisperLlama/train.py", line 222, in <module>
    main()
  File "/home/kyudan/WhisperLlama/train.py", line 202, in main
    train_loss = train_epoch(model, train_loader, optimizer, device, epoch)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kyudan/WhisperLlama/train.py", line 104, in train_epoch
    loss = F.cross_entropy(
           ^^^^^^^^^^^^^^^^
  File "/home/kyudan/anaconda3/envs/py3.12/lib/python3.12/site-packages/torch/nn/functional.py", line 3059, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: Expected input batch_size (3000) to match target batch_size (256).
