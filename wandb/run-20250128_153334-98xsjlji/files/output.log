main train dataset preparing...
lrbirispeech class load dataset...
Resolving data files: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 108/108 [00:00<00:00, 184.29it/s]
Loading dataset shards: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 103/103 [00:00<00:00, 285.00it/s]
main eval dataset preparing...
lrbirispeech class load dataset...
Resolving data files: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 108/108 [00:00<00:00, 747499.72it/s]
Epoch 0:   0%|                                                                                                                                                                                                       | 0/16570 [00:57<?, ?it/s]
Traceback (most recent call last):
  File "/home/kyudan/WhisperLlama/train.py", line 248, in <module>
    main()
  File "/home/kyudan/WhisperLlama/train.py", line 228, in main
    train_loss = train_epoch(model, train_loader, optimizer, device, epoch)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kyudan/WhisperLlama/train.py", line 123, in train_epoch
    outputs = model(
              ^^^^^^
  File "/home/kyudan/anaconda3/envs/py3.12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kyudan/anaconda3/envs/py3.12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kyudan/WhisperLlama/model.py", line 107, in forward
    encoder_outputs = self.encoder(
                      ^^^^^^^^^^^^^
  File "/home/kyudan/anaconda3/envs/py3.12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kyudan/anaconda3/envs/py3.12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kyudan/anaconda3/envs/py3.12/lib/python3.12/site-packages/transformers/models/whisper/modeling_whisper.py", line 1066, in forward
    layer_outputs = encoder_layer(
                    ^^^^^^^^^^^^^^
  File "/home/kyudan/anaconda3/envs/py3.12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kyudan/anaconda3/envs/py3.12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kyudan/anaconda3/envs/py3.12/lib/python3.12/site-packages/transformers/models/whisper/modeling_whisper.py", line 630, in forward
    hidden_states = self.fc2(hidden_states)
                    ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kyudan/anaconda3/envs/py3.12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kyudan/anaconda3/envs/py3.12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kyudan/anaconda3/envs/py3.12/lib/python3.12/site-packages/torch/nn/modules/linear.py", line 116, in forward
    return F.linear(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacity of 11.99 GiB of which 0 bytes is free. Including non-PyTorch memory, this process has 17179869184.00 GiB memory in use. Of the allocated memory 24.85 GiB is allocated by PyTorch, and 398.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
